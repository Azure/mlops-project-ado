{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_data = \"/tmp/prep\"\r\n",
        "model_output = \"/tmp/train\"\r\n",
        "os.makedirs(model_output, exist_ok = True)\r\n",
        "\r\n",
        "regressor__n_estimators = 500\r\n",
        "regressor__bootstrap = 1\r\n",
        "regressor__max_depth = 10\r\n",
        "regressor__max_features = \"auto\" \r\n",
        "regressor__min_samples_leaf = 4\r\n",
        "regressor__min_samples_split = 5"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = \"cost\"\r\n",
        "\r\n",
        "NUMERIC_COLS = [\r\n",
        "    \"distance\",\r\n",
        "    \"dropoff_latitude\",\r\n",
        "    \"dropoff_longitude\",\r\n",
        "    \"passengers\",\r\n",
        "    \"pickup_latitude\",\r\n",
        "    \"pickup_longitude\",\r\n",
        "    \"pickup_weekday\",\r\n",
        "    \"pickup_month\",\r\n",
        "    \"pickup_monthday\",\r\n",
        "    \"pickup_hour\",\r\n",
        "    \"pickup_minute\",\r\n",
        "    \"pickup_second\",\r\n",
        "    \"dropoff_weekday\",\r\n",
        "    \"dropoff_month\",\r\n",
        "    \"dropoff_monthday\",\r\n",
        "    \"dropoff_hour\",\r\n",
        "    \"dropoff_minute\",\r\n",
        "    \"dropoff_second\",\r\n",
        "]\r\n",
        "\r\n",
        "CAT_NOM_COLS = [\r\n",
        "    \"store_forward\",\r\n",
        "    \"vendor\",\r\n",
        "]\r\n",
        "\r\n",
        "CAT_ORD_COLS = [\r\n",
        "]\r\n",
        "\r\n",
        "def main():\r\n",
        "    \r\n",
        "    lines = [\r\n",
        "        f\"Training data path: {prepared_data}\",\r\n",
        "        f\"Model output path: {model_output}\",\r\n",
        "    ]\r\n",
        "\r\n",
        "    for line in lines:\r\n",
        "        print(line)\r\n",
        "\r\n",
        "    print(\"mounted_path files: \")\r\n",
        "    arr = os.listdir(prepared_data)\r\n",
        "    print(arr)\r\n",
        "\r\n",
        "    train_data = pd.read_csv((Path(prepared_data) / \"train.csv\"))\r\n",
        "\r\n",
        "    # Split the data into input(X) and output(y)\r\n",
        "    y_train = train_data[TARGET_COL]\r\n",
        "    X_train = train_data[NUMERIC_COLS + CAT_NOM_COLS + CAT_ORD_COLS]\r\n",
        "    # Train a Linear Regression Model with the train set\r\n",
        "\r\n",
        "    # numerical features\r\n",
        "    numeric_transformer = Pipeline(steps=[\r\n",
        "        ('standardscaler', StandardScaler())])\r\n",
        "\r\n",
        "    # ordinal features transformer\r\n",
        "    ordinal_transformer = Pipeline(steps=[\r\n",
        "        ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\r\n",
        "        ('minmaxscaler', MinMaxScaler())\r\n",
        "    ])\r\n",
        "\r\n",
        "    # nominal features transformer\r\n",
        "    nominal_transformer = Pipeline(steps=[\r\n",
        "        ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\r\n",
        "        ('onehot', OneHotEncoder(sparse=False))\r\n",
        "    ])\r\n",
        "\r\n",
        "    # imputer only for all other features\r\n",
        "    imputer_transformer = Pipeline(steps=[\r\n",
        "        ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\"))\r\n",
        "    ])\r\n",
        "\r\n",
        "    # preprocessing pipeline\r\n",
        "    preprocessor = ColumnTransformer(\r\n",
        "        transformers=[\r\n",
        "            ('numeric', numeric_transformer, NUMERIC_COLS),\r\n",
        "           #('ordinal', ordinal_transformer, CAT_ORD_COLS),\r\n",
        "            ('nominal', nominal_transformer, CAT_NOM_COLS)], # other features are already binary\r\n",
        "            remainder=\"drop\")\r\n",
        "\r\n",
        "    # append regressor to preprocessing pipeline.\r\n",
        "    # now we have a full prediction pipeline.\r\n",
        "    \r\n",
        "    #model = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
        "    #                      ('regressor', RandomForestRegressor(\r\n",
        "    #                          n_estimators = regressor__n_estimators,\r\n",
        "    #                          bootstrap = regressor__bootstrap,\r\n",
        "    #                          max_depth = regressor__max_depth,\r\n",
        "    #                          max_features = regressor__max_features,\r\n",
        "    #                          min_samples_leaf = regressor__min_samples_leaf,\r\n",
        "    #                          min_samples_split = regressor__min_samples_split,\r\n",
        "    #                          random_state=0))])\r\n",
        "\r\n",
        "\r\n",
        "    model = RandomForestRegressor(n_estimators = regressor__n_estimators,\r\n",
        "                                  bootstrap = regressor__bootstrap,\r\n",
        "                                  max_depth = regressor__max_depth,\r\n",
        "                                  max_features = regressor__max_features,\r\n",
        "                                  min_samples_leaf = regressor__min_samples_leaf,\r\n",
        "                                  min_samples_split = regressor__min_samples_split,\r\n",
        "                                  random_state=0)\r\n",
        "\r\n",
        "    mlflow.log_param(\"model\", \"RandomForestRegressor\")\r\n",
        "    mlflow.log_param(\"n_estimators\", regressor__n_estimators)\r\n",
        "    mlflow.log_param(\"bootstrap\", regressor__bootstrap)\r\n",
        "    mlflow.log_param(\"max_depth\", regressor__max_depth)\r\n",
        "    mlflow.log_param(\"max_features\", regressor__max_features)\r\n",
        "    mlflow.log_param(\"min_samples_leaf\", regressor__min_samples_leaf)\r\n",
        "    mlflow.log_param(\"min_samples_split\", regressor__min_samples_split)\r\n",
        "\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "\r\n",
        "    # Predict using the Regression Model\r\n",
        "    yhat_train = model.predict(X_train)\r\n",
        "\r\n",
        "    # Evaluate Regression performance with the train set\r\n",
        "    r2 = r2_score(y_train, yhat_train)\r\n",
        "    mse = mean_squared_error(y_train, yhat_train)\r\n",
        "    rmse = np.sqrt(mse)\r\n",
        "    mae = mean_absolute_error(y_train, yhat_train)\r\n",
        "\r\n",
        "    mlflow.log_metric(\"train r2\", r2)\r\n",
        "    mlflow.log_metric(\"train mse\", mse)\r\n",
        "    mlflow.log_metric(\"train rmse\", rmse)\r\n",
        "    mlflow.log_metric(\"train mae\", mae)\r\n",
        "\r\n",
        "    # Visualize results\r\n",
        "    plt.scatter(y_train, yhat_train,  color='black')\r\n",
        "    plt.plot(y_train, y_train, color='blue', linewidth=3)\r\n",
        "    plt.xlabel(\"Real value\")\r\n",
        "    plt.ylabel(\"Predicted value\")\r\n",
        "    plt.savefig(\"/tmp/train/regression_results.png\")\r\n",
        "    mlflow.log_artifact(\"/tmp/train/regression_results.png\")\r\n",
        "\r\n",
        "    # Save the model\r\n",
        "    pickle.dump(model, open((Path(model_output) / \"model.pkl\"), \"wb\"))\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()\r\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training data path: /tmp/prep\nModel output path: /tmp/train\nmounted_path files: \n['train.csv', 'test.csv', 'val.csv']\n    distance  dropoff_latitude  dropoff_longitude  passengers  \\\n0       1.80         40.678741         -73.980309           1   \n1       0.50         40.754715         -73.925499           1   \n2       0.90         40.669662         -73.911041           1   \n3       2.72         40.774963         -73.892372           1   \n4       6.83         40.756031         -73.945351           1   \n..       ...               ...                ...         ...   \n95      4.36         40.761974         -73.922142           1   \n96      0.90         40.757500         -73.882881           1   \n97      8.30         40.751842         -73.980522           1   \n98      0.53         40.808556         -73.959656           1   \n99      0.78         40.815735         -73.938713           1   \n\n    pickup_latitude  pickup_longitude  pickup_weekday  pickup_month  \\\n0         40.679798        -73.955444               1             1   \n1         40.760818        -73.922935               4             1   \n2         40.664940        -73.923042               4             1   \n3         40.746254        -73.897316               5             1   \n4         40.800102        -73.950050               4             1   \n..              ...               ...             ...           ...   \n95        40.722286        -73.957527               6             1   \n96        40.747601        -73.883423               0             1   \n97        40.840710        -73.940224               2             1   \n98        40.804806        -73.966026               2             1   \n99        40.805866        -73.940529               5             1   \n\n    pickup_monthday  pickup_hour  pickup_minute  pickup_second  \\\n0                 5            9             46             18   \n1                 8           17             49             12   \n2                29           10             28             21   \n3                30           13              8             46   \n4                 8           16             32             18   \n..              ...          ...            ...            ...   \n95               17            4             44              3   \n96               18            3             26             21   \n97                6           17             34             45   \n98               20            0             29             43   \n99                2           18             44             56   \n\n    dropoff_weekday  dropoff_month  dropoff_monthday  dropoff_hour  \\\n0                 1              1                 5             9   \n1                 4              1                 8            17   \n2                 4              1                29            10   \n3                 5              1                30            13   \n4                 4              1                 8            17   \n..              ...            ...               ...           ...   \n95                6              1                17             5   \n96                0              1                18             3   \n97                2              1                 6            18   \n98                2              1                20             0   \n99                5              1                 2            18   \n\n    dropoff_minute  dropoff_second  store_forward  vendor  \n0               57              28              0       2  \n1               52              20              0       1  \n2               34              59              0       1  \n3               20              20              0       2  \n4                5              38              0       2  \n..             ...             ...            ...     ...  \n95               4              44              0       2  \n96              34               7              0       1  \n97               2              21              0       1  \n98              32              49              0       2  \n99              49               2              0       2  \n\n[100 rows x 20 columns]\n"
        },
        {
          "output_type": "error",
          "ename": "AzureMLException",
          "evalue": "AzureMLException:\n\tMessage: UserError: Resource Conflict: ArtifactId ExperimentRun/dcid.329b4ea3-a8ae-44e9-a762-6a3540092d93/regression_results.png already exists.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"UserError: Resource Conflict: ArtifactId ExperimentRun/dcid.329b4ea3-a8ae-44e9-a762-6a3540092d93/regression_results.png already exists.\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAzureMLException\u001b[0m                          Traceback (most recent call last)",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(model, \u001b[38;5;28mopen\u001b[39m((Path(model_output) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/train/regression_results.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/train/regression_results.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m    138\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(model, \u001b[38;5;28mopen\u001b[39m((Path(model_output) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/tracking/fluent.py:606\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m        mlflow.log_artifact(\"features.txt\")\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    605\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m--> 606\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/tracking/client.py:955\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_path, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m    Write a local file or directory to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;03m        is_dir: False\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py:355\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    353\u001b[0m     artifact_repo\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     \u001b[43martifact_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/artifact_repo.py:69\u001b[0m, in \u001b[0;36mAzureMLflowArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m artifact_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_full_artifact_path(artifact_path)\n\u001b[1;32m     68\u001b[0m dest_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_slashes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_dest_path(local_file, artifact_path))\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/run_artifact_repository_client.py:109\u001b[0m, in \u001b[0;36mRunArtifactRepositoryClient.upload_artifact\u001b[0;34m(self, artifact, *args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artifact, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading path artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_artifact_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artifact, IOBase):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading io artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/run_artifact_repository_client.py:102\u001b[0m, in \u001b[0;36mRunArtifactRepositoryClient._upload_artifact_from_path\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(path)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_artifact_from_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/run_artifact_repository_client.py:89\u001b[0m, in \u001b[0;36mRunArtifactRepositoryClient._upload_artifact_from_stream\u001b[0;34m(self, stream, name, content_type)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot upload artifact when run_id is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Construct body\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_empty_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m artifact \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39martifacts[name]\n\u001b[1;32m     91\u001b[0m content_information \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39martifact_content_information[name]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/run_artifact_repository_client.py:67\u001b[0m, in \u001b[0;36mRunArtifactRepositoryClient._create_empty_artifacts\u001b[0;34m(self, paths)\u001b[0m\n\u001b[1;32m     64\u001b[0m         error \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39merrors[artifact_name]\u001b[38;5;241m.\u001b[39merror\n\u001b[1;32m     65\u001b[0m         error_messages\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error\u001b[38;5;241m.\u001b[39mcode,\n\u001b[1;32m     66\u001b[0m                                               error\u001b[38;5;241m.\u001b[39mmessage))\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AzureMLException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_messages))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "\u001b[0;31mAzureMLException\u001b[0m: AzureMLException:\n\tMessage: UserError: Resource Conflict: ArtifactId ExperimentRun/dcid.329b4ea3-a8ae-44e9-a762-6a3540092d93/regression_results.png already exists.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"UserError: Resource Conflict: ArtifactId ExperimentRun/dcid.329b4ea3-a8ae-44e9-a762-6a3540092d93/regression_results.png already exists.\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/train"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}